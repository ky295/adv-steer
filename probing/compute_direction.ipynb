{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Compute difference of means between cautious and non-cautious activations at intermediate layer in transformer residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_activations(file_path):\n",
    "    \"\"\"Load activation data from .npy file\"\"\"\n",
    "    try:\n",
    "        activations = np.load(file_path)\n",
    "        print(f\"Loaded activations with shape: {activations.shape}\")\n",
    "        return activations\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def shuffle_and_split(activations_np):\n",
    "    # Convert to PyTorch tensor\n",
    "    activations_torch = torch.from_numpy(activations_np)\n",
    "\n",
    "    # Shuffle the data\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    indices = torch.randperm(activations_torch.size(0))\n",
    "    activations_shuffled = activations_torch[indices]\n",
    "\n",
    "    # Calculate split point (75% of data)\n",
    "    split_idx = int(activations_torch.size(0) * 0.75)\n",
    "\n",
    "    # Split into train and test\n",
    "    train_data = activations_shuffled[:split_idx]\n",
    "    test_data = activations_shuffled[split_idx:]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_dir = \"../activations/\"\n",
    "layer = 16\n",
    "activations_cautious = load_activations(os.path.join(activations_dir, f\"deepseek_layer_{layer}_cautious_activations.npy\"))\n",
    "activations_noncautious = load_activations(os.path.join(activations_dir, f\"deepseek_layer_{layer}_noncautious_activations.npy\"))\n",
    "\n",
    "train_cautious, test_cautious = shuffle_and_split(activations_cautious)\n",
    "train_noncautious, test_noncautious = shuffle_and_split(activations_noncautious)\n",
    "\n",
    "# Calculate the mean across the first dimension (across all 62 rows)\n",
    "cautious_mean_act = np.mean(activations_cautious, axis=0)\n",
    "noncautious_mean_act = np.mean(activations_cautious, axis=0)\n",
    "\n",
    "cautious_dir = cautious_mean_act - noncautious_mean_act\n",
    "cautious_dir = cautious_dir / cautious_dir.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
